{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbZdwbCCa7ESVs9C2wW2Fg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preethamgoud9/-Nanogpt/blob/main/gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6giZfj2XjbjU",
        "outputId": "f5fe578a-685a-4760-be0d-62365e2c1953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-01 06:43:58--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  4.79MB/s    in 0.2s    \n",
            "\n",
            "2025-03-01 06:43:59 (4.79 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt # first the input data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"input.txt\") as f:              #here im opening the file and storing it in var file for later use\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "s1mYMjVSjql3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"length of characters in dataset:,{len(text)}\")  #here i printed the overall length of characters in the input text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcuJyg4vkGyV",
        "outputId": "1b7b776b-caf8-4a22-9090-a9b11e330d49"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of characters in dataset:,1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])  #i'm printing out the first 1000characters in the input text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSgHjKRLkHoN",
        "outputId": "184e5764-a5fa-44c9-d9b5-057df66bc3e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text))) # here i have taken the text and put in function set to get all the chars in the input data and stored in list and sorted then in an order and put in chars for later use\n",
        "vocab_size = len(chars) # i have stored the length of chars in var named vocab_size\n",
        "print(''.join(chars))\n",
        "print(vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR6tKHCHlFLo",
        "outputId": "519e4e42-6364-45f4-8a00-5efd63a78914"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch:i for i,ch in enumerate(chars)} # Creates a dictionary (stoi) that maps each character in 'chars' to its index.\n",
        "itoc = {i:ch for i,ch in enumerate(chars)}  # here we do the same but the exact opposite take int and convert to char\n",
        "encode = lambda s:[stoi[c] for c in s] # Creates an anonymous function that takes a string 's' and converts each character into its corresponding integer using 'stoi'.\n",
        "decode = lambda l:[itoc[i] for i in l] # here we do the same but the exact opposite but decodes the int to string\n",
        "\n"
      ],
      "metadata": {
        "id": "hjB-1uJvlY2k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode(\"preetham\") #here is what the encode function does"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFWoZ6sjnqmN",
        "outputId": "52aee7e7-3635-4951-991b-6ec839c45912"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[54, 56, 43, 43, 58, 46, 39, 51]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode([54, 56, 43, 43, 58, 46, 39, 51]) #here is what the decode function does"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzDe20k9ojq1",
        "outputId": "3c40c738-fa08-4a84-f6e2-420458edc5e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['p', 'r', 'e', 'e', 't', 'h', 'a', 'm']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text),dtype =torch.long)  # i have encoded the whole input text into in teger of type long(Which is int64) and converted it into tensor(one dimenional) and stored in var data\n",
        "print(data.shape ,data.dtype)\n",
        "print(data[:1000])  #here im outputting the first 1000int output which is encoded from string to int by slicing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLvYmsxYqnAk",
        "outputId": "46c35f16-e49f-4a53-b6df-efac2ecf58d2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))   # here im spliting the data into two sets as train data and validation data into 90 10 percents\n",
        "train_data = data[:n]    #here im slicing from beginning to n which 90percent of the data cuz of n\n",
        "val_data = data[n:]      #here im slicing the data from the index n to the end"
      ],
      "metadata": {
        "id": "HUHjloPB0Ja5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8    # here instead of taking the entire text(dataset) we are dealing in small chucks named block_size\n",
        "train_data[:block_size+1] #here we are taking the block_size plus 1 set"
      ],
      "metadata": {
        "id": "pA3bEIWo0buq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab3124e-1d42-41e3-b00e-0f65adf0d9d3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l-jKuXwpSJ4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"if the input is {context} the target is : {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q63baNL4PXJZ",
        "outputId": "a4121279-854d-4b1a-cc60-b093e02799b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if the input is tensor([18]) the target is : 47\n",
            "if the input is tensor([18, 47]) the target is : 56\n",
            "if the input is tensor([18, 47, 56]) the target is : 57\n",
            "if the input is tensor([18, 47, 56, 57]) the target is : 58\n",
            "if the input is tensor([18, 47, 56, 57, 58]) the target is : 1\n",
            "if the input is tensor([18, 47, 56, 57, 58,  1]) the target is : 15\n",
            "if the input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is : 47\n",
            "if the input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is : 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is manual implementation of dataset and dataloader in production we can use classes such as dataset and dataloader\n",
        "#this is manuallly implementing the the mini batch to improve the speed and efficient through parallization of data spliting and training\n",
        "#can be known as mini batch gradient descent\n",
        "\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split == \"train\" else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x,y\n",
        "\n",
        "xb,yb = get_batch(\"train\")\n",
        "print(\"inputs;\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "print(\"-\"*25)\n",
        "\n",
        "\n",
        "for b in range(batch_size):\n",
        "  for t in range(block_size):\n",
        "    context = xb[b,:t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f\"when the input is {context.tolist()} the target is {target}\")"
      ],
      "metadata": {
        "id": "MBr-H9iWPass",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa161cc9-f11f-48be-845a-16d85ca85ca6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs;\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "-------------------------\n",
            "when the input is [24] the target is 43\n",
            "when the input is [24, 43] the target is 58\n",
            "when the input is [24, 43, 58] the target is 5\n",
            "when the input is [24, 43, 58, 5] the target is 57\n",
            "when the input is [24, 43, 58, 5, 57] the target is 1\n",
            "when the input is [24, 43, 58, 5, 57, 1] the target is 46\n",
            "when the input is [24, 43, 58, 5, 57, 1, 46] the target is 43\n",
            "when the input is [24, 43, 58, 5, 57, 1, 46, 43] the target is 39\n",
            "when the input is [44] the target is 53\n",
            "when the input is [44, 53] the target is 56\n",
            "when the input is [44, 53, 56] the target is 1\n",
            "when the input is [44, 53, 56, 1] the target is 58\n",
            "when the input is [44, 53, 56, 1, 58] the target is 46\n",
            "when the input is [44, 53, 56, 1, 58, 46] the target is 39\n",
            "when the input is [44, 53, 56, 1, 58, 46, 39] the target is 58\n",
            "when the input is [44, 53, 56, 1, 58, 46, 39, 58] the target is 1\n",
            "when the input is [52] the target is 58\n",
            "when the input is [52, 58] the target is 1\n",
            "when the input is [52, 58, 1] the target is 58\n",
            "when the input is [52, 58, 1, 58] the target is 46\n",
            "when the input is [52, 58, 1, 58, 46] the target is 39\n",
            "when the input is [52, 58, 1, 58, 46, 39] the target is 58\n",
            "when the input is [52, 58, 1, 58, 46, 39, 58] the target is 1\n",
            "when the input is [52, 58, 1, 58, 46, 39, 58, 1] the target is 46\n",
            "when the input is [25] the target is 17\n",
            "when the input is [25, 17] the target is 27\n",
            "when the input is [25, 17, 27] the target is 10\n",
            "when the input is [25, 17, 27, 10] the target is 0\n",
            "when the input is [25, 17, 27, 10, 0] the target is 21\n",
            "when the input is [25, 17, 27, 10, 0, 21] the target is 1\n",
            "when the input is [25, 17, 27, 10, 0, 21, 1] the target is 54\n",
            "when the input is [25, 17, 27, 10, 0, 21, 1, 54] the target is 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb)    #this is our input to the transformer"
      ],
      "metadata": {
        "id": "O5SQKFkwSu04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1fa5028-59ce-4844-b3d8-2059da42736a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FANRBbuNyZFl",
        "outputId": "14c7adb2-f9f9-4a49-8dfd-12901866e9de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
            "['\\n', 'S', 'r', '?', 'q', 'P', '-', 'Q', 'W', 'k', 't', 'X', 'o', 'L', '&', 'j', 'L', 'D', 'J', 'g', 'O', 'L', 'V', 'z', \"'\", 'R', 'I', 'o', 'D', 'q', 'H', 'd', 'h', 's', 'V', '&', 'v', 'L', 'L', 'x', 'a', 't', 'j', 's', 'c', 'M', 'p', 'w', 'L', 'E', 'R', 'S', 'P', 'y', 'a', 'o', '.', 'q', 'f', 'z', 's', '$', 'Y', 's', '$', 'z', 'F', '-', 'w', ',', ';', 'e', 'E', 'k', 'z', 'x', 'j', 'g', 'C', 'K', 'F', 'C', 'h', 's', '!', 'i', 'W', 'W', '.', 'O', 'b', 'z', 'D', 'n', 'x', 'A', ' ', 'M', 's', '$', '3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "7AzuiYzF0kKz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(100): # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJKOh-mlcvL-",
        "outputId": "61f0cf9a-d5b0-435f-a5e7-4242b5bbd076"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.587916374206543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEGyGfvLcxV6",
        "outputId": "f494f8dd-9b5d-411c-f9b3-0e03f5c43d70"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', 'x', 'i', 'K', 'i', '-', 'R', 'J', ':', 'C', 'g', 'q', 'V', 'u', 'U', 'a', '!', 'U', '?', 'q', 'M', 'H', '.', 'u', 'k', '!', 's', 'C', 'u', 'M', 'X', 'v', 'v', '!', 'C', 'J', 'F', 'f', 'x', ';', 'L', 'g', 'R', 'y', 'J', 'k', 'n', 'O', 'E', 't', 'i', '.', '?', 'I', '&', '-', 'g', 'P', 'l', 'L', 'y', 'u', 'l', 'I', 'd', '?', 'X', 'l', 'a', 'I', 'n', 'Q', \"'\", 'q', ',', 'l', 'T', '$', '\\n', '3', 'Q', '&', 's', 'G', 'l', 'v', 'H', 'Q', '?', 'm', 'q', 'S', 'q', '-', 'e', 'O', 'N', '\\n', 'x', '?', 'S', 'P', ' ', 'f', 'U', 'A', 'f', 'C', 'A', 'u', 'C', 'X', ':', 'b', 'O', 'l', 'g', 'i', 'R', 'Q', 'W', 'N', ':', 'M', 'p', 'h', 'a', 'w', '\\n', 't', 'R', 'L', 'K', 'u', 'Y', 'X', 'E', 'a', 'A', 'X', 'x', 'r', 'c', 'q', '-', 'g', 'C', 'U', 'z', 'e', 'h', '3', 'w', '!', 'A', 'c', 'y', 'a', 'y', 'l', 'g', 'Y', 'W', 'j', 'm', 'J', 'M', '?', 'U', 'z', 'w', ':', 'i', 'n', 'a', 'Y', ',', ':', 'C', '&', 'O', 'E', 'C', 'W', ':', 'v', 'm', 'G', 'G', 'J', 'A', 'n', '3', 'o', 'n', 'A', 'u', 'M', 'g', 'i', 'a', '!', 'm', 's', '$', 'V', 'b', ' ', 'q', '-', 'g', 'C', 'O', 'c', 'P', 'c', 'U', 'h', 'O', 'n', 'x', 'J', 'G', 'U', 'G', 'S', 'P', 'J', 'W', 'T', ':', '.', '?', 'u', 'j', 'm', 'J', 'F', 'o', 'i', 'N', 'L', '&', 'A', \"'\", 'D', 'x', 'Y', ',', 'p', 'r', 'Z', '?', 'q', 'd', 'T', ';', 'h', 'o', 'o', \"'\", 'd', 'H', 'o', 'o', 'X', 'X', 'l', 'x', 'f', \"'\", 'W', 'k', 'H', 'K', '&', 'u', '3', 'Q', '?', 'r', 'q', 'U', 'i', '.', 'k', 'z', ';', '?', 'Y', 'x', '?', 'C', '&', 'u', '3', 'Q', 'b', 'f', 'z', 'x', 'l', 'y', 'h', \"'\", 'V', 'l', ':', 'z', 'y', 'x', 'j', 'K', 'X', 'g', 'C', '?', '\\n', 'l', 'v', \"'\", 'Q', 'K', 'F', 'i', 'B', 'e', 'v', 'i', 'N', 'x', 'O', \"'\", 'm', '!', 'U', 'p', 'm', '$', 's', 'r', 'm', '&', 'T', 'q', 'V', 'i', 'q', 'i', 'B', 'D', '3', 'H', 'B', 'P', '!', 'j', 'u', 'E', 'O', 'p', 'm', 'Z', 'J', 'y', 'F', '$', 'F', 'w', 'f', 'y', '!', 'P', 'l', 'v', 'W', 'P', 'F', 'C', '\\n', '&', 'W', 'D', 'd', 'P', '!', 'K', 'o', ',', 'p', 'x', '\\n', 'x', '\\n', 't', 'R', 'E', 'O', 'E', ';', 'A', 'J', '.', 'B', 'e', 'X', 'k', 'y', 'l', 'O', 'V', 'D', '3', 'K', 'H', 'p', '$', 'e', '?', 'n', 'D', ',', '.', 'S', 'F', 'b', 'W', 'W', 'I', \"'\", 'u', 'b', 'c', 'L', '!', 'q', '-', 't', 'U', ';', 'a', 'X', 'm', 'J', '&', 'u', 'G', 'X', 'H', 'x', 'J', 'X', 'I', '&', 'Z', '!', 'g', 'H', 'R', 'p', 'a', 'j', 'j', ';', 'l', '.', '\\n', 'p', 'T', 'E', 'r', 'I', 'B', 'j', 'x', ';', 'J', 'K', 'I', 'g', 'o', 'C', 'n', 'L', 'G', 'X', 'r', 'J', 'S', 'P', '!', 'A', 'U', '-', 'A', 'c', 'b', 'c', 'z', 'R', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRhvzO0jcy4F",
        "outputId": "6e2f5c81-0cd2-4c7f-e366-1a348c294855"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYILbX9ac3w5",
        "outputId": "8514b293-38f1-475b-d707-dd974bef0179"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n"
      ],
      "metadata": {
        "id": "6wfHBjd2c5wy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbxALIW3c7Wm",
        "outputId": "e534f76b-bc09-4dd6-dc6c-15374fcbdb22"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwuAbG1rc80H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}